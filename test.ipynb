{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/layoutlm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from transformers import MarianMTModel, MarianTokenizer # MT: Machine Translation\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math, random\n",
    "from einops import rearrange\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/layoutlm/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ko-en')\n",
    "model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ko-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eos_idx =  0\n",
      "pad_idx =  65000\n"
     ]
    }
   ],
   "source": [
    "eos_idx = tokenizer.eos_token_id\n",
    "pad_idx = tokenizer.pad_token_id\n",
    "print(\"eos_idx = \", eos_idx)\n",
    "print(\"pad_idx = \", pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 # 논문에선 2.5만 token이 한 batch에 담기게 했다고 함.\n",
    "LAMBDA = 0 # l2-Regularization를 위한 hyperparam. # 저장된 모델\n",
    "EPOCH = 15 # 저장된 모델\n",
    "# max_len = 512 # model.model.encoder.embed_positions 를 보면 512로 했음을 알 수 있다.\n",
    "max_len = 100 # 너무 긴거 같아서 자름 (GPU 부담도 많이 덜어짐)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx) # pad token 이 출력 나와야하는 시점의 loss는 무시 (즉, label이 <pad> 일 때는 무시) # 저장된 모델\n",
    "scheduler_name = 'Noam'\n",
    "#### Noam ####\n",
    "# warmup_steps = 4000 # 이건 논문에서 제시한 값 (총 10만 step의 4%)\n",
    "warmup_steps = 1000 # 데이터 수 * EPOCH / BS = 총 step 수 인것 고려 # 저장된 모델\n",
    "LR_scale = 0.5 # Noam scheduler에 peak LR 값 조절을 위해 곱해질 녀석 # 저장된 모델\n",
    "#### Cos ####\n",
    "LR_init = 5e-4\n",
    "T0 = 1500 # 첫 주기\n",
    "T_mult = 2 # 배 만큼 주기가 길어짐 (1보다 큰 정수여야 함)\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65001\n"
     ]
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 좀 사이즈 줄인 모델 (훈련된 input_embedding, fc_out 사용하면 사용 불가)\n",
    "n_layers = 3\n",
    "d_model = 256\n",
    "d_ff = 512\n",
    "n_heads = 8\n",
    "drop_p = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁확실히', '▁띄', '어', '쓰기', '▁기준으로', '▁토', '크', '나이', '징', '을', '▁하는', '▁것', '▁같', '진', '▁않다', '.']\n",
      "['▁여러분들', '▁차례', '!']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(\"확실히 띄어쓰기 기준으로 토크나이징을 하는 것 같진 않다.\"))\n",
    "print(tokenizer.tokenize(\"여러분들 차례!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 헐! 대박 쩐다!\n",
      "AI 번역: Oh, my God! That's awesome!\n",
      "['▁헐', '!', '▁대박', '▁', '쩐', '다', '!']\n",
      "tensor([[19458,    28, 41999,     9, 58809,   161,    28,     0]])\n"
     ]
    }
   ],
   "source": [
    "input_text = \"헐! 대박 쩐다!\"\n",
    "input_tokens = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "translated_tokens = model.generate(input_tokens, max_new_tokens=max_len)\n",
    "translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"입력:\", input_text)\n",
    "print(\"AI 번역:\", translated_text)\n",
    "\n",
    "tokens = tokenizer.tokenize(\"헐! 대박 쩐다!\")\n",
    "print(tokens)\n",
    "print(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1r4ZnFJOStyBlNRx7snBQ-Iq2GNyJKL6t\n",
      "To: /home/yjhwang/workspace/Transformer/대화체.xlsx\n",
      "100%|██████████████████████████████████████| 9.57M/9.57M [00:00<00:00, 17.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# !gdown https://drive.google.com/uc?id=1r4ZnFJOStyBlNRx7snBQ-Iq2GNyJKL6t -O '대화체.xlsx'\n",
    "# data = pd.read_excel('대화체.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('대화체.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48500\n",
      "1000\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, '원문'], self.data.loc[idx, '번역문']\n",
    "    \n",
    "custom_DS = CustomDataset(data)\n",
    "\n",
    "train_DS, val_DS, test_DS = torch.utils.data.random_split(custom_DS, [97000, 2000, 1000])\n",
    "\n",
    "train_DL = torch.utils.data.DataLoader(train_DS, batch_size = BATCH_SIZE, shuffle=True)\n",
    "val_DL = torch.utils.data.DataLoader(val_DS, batch_size = BATCH_SIZE, shuffle=True)\n",
    "test_DL = torch.utils.data.DataLoader(test_DS, batch_size = BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(len(train_DL))\n",
    "print(len(val_DL))\n",
    "print(len(test_DL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        return self.data.loc[index, '원문'], self.data.loc[index, '번역문']\n",
    "    \n",
    "custom_DS = CustomDataset(data)\n",
    "train_DS, val_DS, test_DS = torch.utils.data.random_split(custom_DS, [97000,2000,1000])\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_DL = torch.utils.data.DataLoader(train_DS, BATCH_SIZE, shuffle=True)\n",
    "val_DL = torch.utils.data.DataLoader(val_DS, BATCH_SIZE, shuffle=True)\n",
    "test_DL = torch.utils.data.DataLoader(test_DS, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스: 12605\n",
      "원문: 4월 7일부터 한 주간 있다가 올 거 같아.\n",
      "번역문: It'll probably be for a week starting on the 7th of April.\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "src_text, trg_text = train_DS[idx]\n",
    "\n",
    "print(f\"인덱스: {test_DS.indices[idx]}\")\n",
    "print(f\"원문: {src_text}\")\n",
    "print(f\"번역문: {trg_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('다른 사람들이 입어보고 한 진열제품은 가져가기가 그런데, 아니면 금액을 깎아주세요.', '진짜 모차렐라 치즈를 듬뿍 넣어서 만든 느낌이야.', '어떡할래? 우리 그냥 다른 음식점으로 갈까?', '아니에요, 점수에 의구심이 든다면 당연히 확인해야지요.', '영상 자료를 틀어야 해서 시청각실로 함께 가시죠.', '큰길 사거리에서 오른쪽 길로 가서 5분 정도 걸어가면 있습니다.', '네, 지금 바로 검은색으로 변경해드리도록 하겠습니다.', '다음 주까지 필요한데 가능한지 확인 좀 해주세요.', '그 터키 공장은 우리와 이번에 처음 거래하는 업체이니, 저희 쪽에서는 딱히 방법이 없어요.', '지방을 제거해서 꺼진 부위에 메워주는 거예요.', '제가 지금 바로 차를 타는데, 효과가 있을까요?', '벌써요? 그렇다면 바다 전망이 아니라도 경치가 좋은 객실로 부탁드려요.', '저기에 안내해주시는 분이 있으니까 한번 여쭤볼까?', '정지를 푸는 것은 가능한데, 지금 신규 카드가 발송 중인데 괜찮으실까요?', '저번 영화는 재미있게 봤는데, 이 영화는 어떨지 모르겠네.', '이번 달 예산이 좀 빠듯한데, 어디 저렴한 미용실 없나?')\n",
      "(\"I'm relucted to buy the displayed product since it has been worn by someone else, or please offer a discount.\", \"It's like they made it with real mozzarella cheese.\", 'What do you want to do? Shall we go to another restaurant?', 'No, if you have any doubts about the score, you should check it out to make sure.', \"Let's go to the audiovisual room together because we have to turn on the video.\", 'Walk 5 minutes from the intersection in the main street to the right.', \"Yes, I'll change it to black right now.\", \"I need it by next week, and please check if it's possible.\", 'The Turkish factory is our first business partner this time, so we have no choice.', \"It's removing fat and filling the hollow parts with it.\", 'I am going to get into a car right now, will it be effective?', \"Already? Then I'd like to book a room with beautiful scenery.\", \"There's a guide over there, should we go ask him?\", \"It's possible to unfreeze it, but we're currently sending you a new card right now, is that alright?\", \"I really enjoyed that movie before, I don't know what this movie will be like.\", 'I am a bit short of money this month, is there any cheap hair salon?')\n",
      "16\n",
      "16\n",
      "torch.Size([16, 21])\n",
      "torch.Size([16, 54])\n",
      "====================================================================================================\n",
      "tensor([    0, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "        65000, 65000, 65000, 65000, 65000, 65000])\n",
      "tensor([ True, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False])\n",
      "</s> I'm relucted to buy the displayed product since it has been worn by someone else, or please offer a discount.</s>\n",
      "====================================================================================================\n",
      "디코더 입력:\n",
      "\n",
      "</s> Walk 5 minutes from the intersection in the main street to the right.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "디코더 출력:\n",
      "\n",
      "Walk 5 minutes from the intersection in the main street to the right.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "src_texts, trg_texts = next(iter(train_DL))\n",
    "\n",
    "print(src_texts)\n",
    "print(trg_texts)\n",
    "print(len(src_texts))\n",
    "print(len(trg_texts))\n",
    "\n",
    "src = tokenizer(src_texts, padding=True, truncation=True, max_length=max_len, return_tensors='pt', add_special_tokens=False).input_ids\n",
    "trg_texts = ['</s>' + s for s in trg_texts]\n",
    "trg = tokenizer(trg_texts, padding=True, truncation=True, max_length=max_len, return_tensors='pt', add_special_tokens=True).input_ids\n",
    "\n",
    "print(src.shape)\n",
    "print(trg.shape)\n",
    "print(\"=\"*100)\n",
    "print(trg[:,-1])\n",
    "print(trg[:,-1]==eos_idx)\n",
    "# print(tokenizer.decode(trg[trg[:,-1]==eos_idx,:])[0])\n",
    "# print(trg[trg[:,-1]==eos_idx])\n",
    "# print(trg[trg[:,-1]==eos_idx,:])\n",
    "# print(trg[trg[:,-1]==eos_idx][0])\n",
    "print(tokenizer.decode(trg[trg[:,-1]==eos_idx][0]))\n",
    "print(\"=\"*100)\n",
    "print(\"디코더 입력:\\n\")\n",
    "# print(trg[5,:-1])\n",
    "print(tokenizer.decode(trg[5,:-1]))\n",
    "print(\"디코더 출력:\\n\")\n",
    "# print(trg[5,1:])\n",
    "print(tokenizer.decode(trg[5,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 바지 허리 안쪽에 제품명이 적혀 있을 텐데 불러주시겠어요?\n",
      "정답: There should be the product name written on the inside of the pants' waist so could you please tell me?\n",
      "AI의 번역: <pad> There's a product name in the back of your pants, so can you call it?</s>\n"
     ]
    }
   ],
   "source": [
    "# 내가 쓸 train data에 대해서 MarianMTmodel 이 잘 번역하는지 확인\n",
    "src_text, trg_text = train_DS[7]\n",
    "print(f\"입력: {src_text}\")\n",
    "print(f\"정답: {trg_text}\")\n",
    "\n",
    "src = tokenizer.encode(src_text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "# print(src)\n",
    "translated_tokens = model.generate(src, max_new_tokens=max_len)\n",
    "translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=False)\n",
    "\n",
    "print(f\"AI의 번역: {translated_text}\") # 디코더 첫 입력으로 <pad> 토큰을 넣었음. (<pad>를 <sos>로 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHA(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.fc_q = nn.Linear(d_model,d_model)\n",
    "        self.fc_k = nn.Linear(d_model,d_model)\n",
    "        self.fc_v = nn.Linear(d_model,d_model)\n",
    "        self.fc_o = nn.Linear(d_model,d_model)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.tensor(d_model/n_heads))\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.fc_q(Q)\n",
    "        K = self.fc_q(K)\n",
    "        V = self.fc_q(V)\n",
    "\n",
    "        Q = rearrange(Q, '개 단 (헤, 차) -> 개 헤 단 차', 헤=self.n_heads)\n",
    "        K = rearrange(K, '개 단 (헤, 차) -> 개 헤 단 차', 헤=self.n_heads)\n",
    "        V = rearrange(V, '개 단 (헤, 차) -> 개 헤 단 차', 헤=self.n_heads)\n",
    "\n",
    "        attention_score = Q @ K.transpose(-2,-1) / self.scale # 개헤단단\n",
    "\n",
    "        if mask is not None:\n",
    "            attention_score[mask] = -1e10\n",
    "\n",
    "        attention_weights = torch.softmax(attention_score, dim=-1) # 개헤단단\n",
    "\n",
    "        attention = attention_weights @ V # 개헤단차\n",
    "\n",
    "        x = rearrange(attention, '개 헤 단 차 -> 개 단 (헤 차)') #개헤단차 -> 개단차\n",
    "        x = self.fc_o(x) # 개단차\n",
    "\n",
    "        return x, attention_weights\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, drop_p):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(nn.Linear(d_model, d_model),\n",
    "                                    nn.ReLu(),\n",
    "                                    nn.Dropout(drop_p), # 논문에는 명시되어 있지 않지만, overfiiting 에 취약한 부분이랑 도입함\n",
    "                                    nn.Linear(d_ff, d_model))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "layoutlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
